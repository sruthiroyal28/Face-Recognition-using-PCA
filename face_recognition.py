# -*- coding: utf-8 -*-
"""face_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XUn8yKu3n60otsNv1cehpavNG1LEC6yf
"""

import cv2

image_path = 'Charlie_Chaplin_portrait.jpg'

#reading the image
image = cv2.imread(image_path)

#reads the image in BGR format
print(image.shape)
# if the dimensions are (x,y,3) then it repersent that image is color i.e it has three channels - blue,green and red (BGR).

# converting color image into gray image to improve computational accuracy
gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)

print(gray_image.shape)

#LOADING PRE-TRAINED HAAR CASCADE CLASSIFIER PRESENT IN OPENCV
#haarcascade_frontalface_default.xml - designed especially to recognise faces
face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

#to perform face detection
face = face_classifier.detectMultiScale(gray_image , scaleFactor=1.1 , minNeighbors=4 , minSize=(40,40))

# bounding boxes - visual rep of detected faces , making it easy to identify and locate regio where face detection algorithm has recognized containing faces.
for (x,y,w,h) in face:
    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),4)#4 indicate thickness

#display image with detected faces.
#convert BGR to RGB
image_or = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)

import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))
plt.imshow(image_or)
plt.axis('off')

#to detect face in the vedio
# 0 - represents the we use default camera on  device.
video_capture = cv2.VideoCapture(0)

#indetifying faces in vedio stream
def detect_bounding_box(video):
  g_image = cv2.cvtColor(video,cv2.COLOR_BGR2GRAY)
  face = face_classifier.detectMultiScale(g_image , 1.1 , 5 , minSize=(40,40))#contain information about detected faces such as co-ordinates
  for (x,y,w,h) in face:
    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),4)#4 indicate thickness
  return face

#creating indefinite loop that captures vedio frame from webcam and apply face detection
while True:

    result, video_frame = video_capture.read()  # read frames from the video
    #result - boolean values which represnts we if the frame is succesfully captured or not
    #viedo_frame - contains actual frame
    if result is False:#frame wasn't read properly
        break  # terminate the loop if the frame is not read successfully

    # apply the function we created to the video frame
    faces = detect_bounding_box(
        video_frame
    )  # apply the function we created to the video frame

    # display the processed frame in a window named "My Face Detection Project"
    cv2.imshow(
        "My Face Detection Project", video_frame
    )


    #waitKey function is used to wait for a key event for a specified amount of time. Here, it waits for 1 millisecond.
    # when q key is pressed it will stop video capturing
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

video_capture.release()
cv2.destroyAllWindows()

import cv2
import matplotlib.pyplot as plt


face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
video_capture = cv2.VideoCapture(0)

#indetifying faces in vedio stream
def detect_bounding_box(video):
  g_image = cv2.cvtColor(video,cv2.COLOR_BGR2GRAY)
  face = face_classifier.detectMultiScale(g_image , 1.1 , 5 , minSize=(40,40))#contain information about detected faces such as co-ordinates
  for (x,y,w,h) in face:
    cv2.rectangle(g_image,(x,y),(x+w,y+h),(0,255,0),4)#4 indicate thickness
  return face

#creating indefinite loop that captures vedio frame from webcam and apply face detection
while True:

    result, video_frame = video_capture.read()  # read frames from the video
    #result - boolean values which represnts we if the frame is succesfully captured or not
    #viedo_frame - contains actual frame
    if result is False:#frame wasn't read properly
        break  # terminate the loop if the frame is not read successfully

    # apply the function we created to the video frame
    faces = detect_bounding_box(
        video_frame
    )  # apply the function we created to the video frame

    # display the processed frame in a window named "My Face Detection Project"
    cv2.imshow(
        "My Face Detection Project", video_frame
    )


    #waitKey function is used to wait for a key event for a specified amount of time. Here, it waits for 1 millisecond.
    # when q key is pressed it will stop video capturing
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

video_capture.release()
cv2.destroyAllWindows()

import cv2

image_path = 'ppl.jpg'

#reading the image
image = cv2.imread(image_path)

#reads the image in BGR format
print(image.shape)
#if the dimensions are (x,y,3) then it repersent that image is color i.e it has three channels - blue,green and red (BGR).

#converting color image into gray image to improve computational accuracy
gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)

print(gray_image.shape)

#LOADING PRE-TRAINED HAAR CASCADE CLASSIFIER PRESENT IN OPENCV
#haarcascade_frontalface_default.xml - designed especially to recognise faces
face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

#to perform face detection
face = face_classifier.detectMultiScale(gray_image , scaleFactor=1.1 , minNeighbors=4 , minSize=(40,40))

#bounding boxes - visual rep of detected faces , making it easy to identify and locate regio where face detection algorithm has recognized containing faces.
for (x,y,w,h) in face:
    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),4)#4 indicate thickness

#display image with detected faces.
#convert BGR to RGB
image_or = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)

import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))
plt.imshow(image_or)
plt.axis('off')

import cv2
from google.colab.patches import cv2_imshow
# Reading the image
img = cv2.imread('ppl.jpg')

# Converting image to grayscale
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Loading the required Haar Cascade XML classifier file
# Adjust the path to the XML file according to your directory structure
haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Applying the face detection method on the grayscale image
faces_rect = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=4, minSize=(40, 40))

# Iterating through rectangles of detected faces
for (x, y, w, h) in faces_rect:
    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)

cv2_imshow( img)

cv2.waitKey(0)